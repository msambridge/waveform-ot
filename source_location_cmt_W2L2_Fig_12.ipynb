{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python examples in Sambridge et al. (2022): Displacement seismogram inversion for source parameters\n",
    "\n",
    "This Jupyter notebook contains python code to illustrate calculations made in \n",
    "\n",
    "Sambridge, Jackson & Valentine (2022), [Geophysical Inversion and Optimal Transport](https://doi.org/10.1093/gji/ggac151), *Geophysical Journal International*.\n",
    "\n",
    "This notebook demonstrates calculations involving waveform inversion for source locatuon and cmt parameters. It produces components of Figures 9, 10, 11 & 12 of Sambridge et al. (2022).\n",
    "\n",
    "Some results are computationally expensive and by default have been replaced with reading in results from pickle files. These are:\n",
    "- calcualtion of wavefom misfit surfaces for Wasserstein and L2 since they involve repeated waveform calculations for many locations. \n",
    "- repeat locations from differing starting models\n",
    "\n",
    "If executing the pickle file contained in this package an option below is provided to use *on the fly* mode, and then write your own pickle files for future use in *read results* mode.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimal Transport libraries\n",
    "\n",
    "This notebook makes use of the following python scripts:\n",
    "\n",
    "- `loc_cmt_util.py` contains various utility plot routines used in this notebook, but also acts as an interface to two independent libraries: \n",
    "\n",
    "- `OTlib.py` containing the author's Optimal Transport calculation library for 1D and 2D densities fields together with derivatives.\n",
    "\n",
    "- `FingerprintLib.py` containing routines required to calculate nearest distance fields and 2D densities for time series together with their derivatives of density field with respect to time series amplitude."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seismogram Software pyprop8\n",
    "\n",
    "This notebook makes use of Andrew Valentine's pyprop8 implementation of of the seismogram calculation algorithm set out in [O'Toole & Woodhouse (2011)](https://doi.org/10.1111/j.1365-246X.2011.05210.x), together with the source derivatives set out in [O'Toole, Valentine & Woodhouse (2012)](https://doi.org/10.1111/j.1365-246X.2012.05608.x). To run this notebook this package\n",
    "needs to be installed separately. Instructions of how to do this appear [here](https://pypi.org/project/pyprop8/).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Source location and centroid moment tensor inversion with $L_2$ and $W_2^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pyprop8 as pp\n",
    "from pyprop8.utils import rtf2xyz,make_moment_tensor\n",
    "from tqdm import tqdm \n",
    "import time as timer\n",
    "from matplotlib import cm\n",
    "from scipy.optimize import minimize\n",
    "from libs import myGP as gp\n",
    "import pickle as pickle\n",
    "from libs import loc_cmt_util as cmt_util\n",
    "from libs import loc_cmt_util_opt as cmt_util_opt\n",
    "cmt_util_opt.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recordresult(x):\n",
    "    from libs import loc_cmt_util_opt\n",
    "\n",
    "    mis = loc_cmt_util_opt.opt_history_data[-1][0]\n",
    "    Mxyz = loc_cmt_util_opt.opt_history_data[-1][-1]\n",
    "    index = len(loc_cmt_util_opt.opt_history_data)\n",
    "    if(invopt['precon']):\n",
    "        loc_cmt_util_opt.opt_history.append([x*invopt['mscal'],mis,index,Mxyz])\n",
    "    else:\n",
    "        loc_cmt_util_opt.opt_history.append([x,mis,index,Mxyz])\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Earth model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Velocity model is from table 1 of O'Toole et al. (2012).\n",
    "\n",
    "This earth model was used by Kobayashi et al.\n",
    "(2006) in their finite fault inversions of HRGPS data for the 2005 Fukuoka earthquake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_table1 = np.array([[0.1,3.2,2.0,2.1],[1.9,5.15,2.85,2.5],[3.0,5.5,3.2,2.6],[13.0,6.0,3.46,2.7],[14.0,6.7,3.87,2.8],[np.inf,7.7,4.3,3.3]])\n",
    "model = pp.LayeredStructureModel(model_table1,interface_depth_form = False)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seismic Source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seismic source is 2005 Mw 6.6 Fukuoka earthquake. \n",
    "\n",
    "We use the CMT solution of the Global CMT catalogue (strike=302, dip=88, rake=-14, with $M_o = 0.93E19$ Nm.\n",
    "1 Nm = 10,000,000.00 dyne cm.\n",
    "\n",
    "We also use a symmetricl trapezoidal source time function with $T_{rise}=3, T_{rupt}=6$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up seismic source\n",
    "Mo = 0.93e19 # source moment in Nm\n",
    "dynecm2moment = 1.0E-20 # Conversion factor from dyne-cm to moment argument value\n",
    "Nm2moment = 1.0E-13 # Conversion factor from Nm to moment argument value\n",
    "sourceLat = 0.\n",
    "sourceLong = 0.\n",
    "source = pp.PointSource(0.,0.,10.,rtf2xyz(make_moment_tensor(302,88,-14,Mo*Nm2moment,0,0)),np.zeros((3,1)),0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Receiver Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test set of stations similar to Figure 3 of O'Toole et al. (2012)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we input an irregular network of stations locations using the *ListofReceivers* routine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlocations_all = np.array([10.,30.,50.,-15.,8.,25.,-25.,55.,80.,75.,-70.])\n",
    "ylocations_all = np.array([-75.,-77.,-70.,-50.,-46.,-42.,-25.,-26.,-23.,-5.,30.])\n",
    "xlocations = xlocations_all\n",
    "ylocations = ylocations_all\n",
    "nr = 11 # Number of receivers\n",
    "nc = 3 # Number of components\n",
    "xtrue,ytrue,ztrue = 1., 1., 20. # true source location\n",
    "mtrue = np.array([xtrue,ytrue,ztrue])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot actual station locations\n",
    "s = (xlocations,ylocations)\n",
    "s_a = (xlocations_all,ylocations_all)\n",
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "plt.subplot(111,aspect='equal')\n",
    "plt.title(\"Desired Station network\")\n",
    "plt.plot(s_a[0][0],s_a[1][0],'k^',label='Receivers',markersize=10)\n",
    "plt.plot(s_a[0],s_a[1],'k^',markersize=10)\n",
    "plt.plot(s[0],s[1],'g^',markersize=10)\n",
    "plt.xlabel(' East (km)')\n",
    "plt.ylabel(' North (km)')\n",
    "plt.plot(xtrue,ytrue,'r*',label='Source',markersize=10)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the source station geometry seen in Figure 9 of Sambridge et al. (2022). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note zero frequency displacement seismograms, refereed to as GPS seismograms by O'Toole et al. (2012)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observed displacement seismograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate displacement seismograms from true location of source and then add correlated Gaussian noise. This is then used as `data' below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate noiseless displacement seismograms of true solution\n",
    "nt = 61                       # Number of timesteps\n",
    "timestep = 1.0                # time spacing\n",
    "prop8data = {'model':model,'sdrm':[302,88,-14,Mo],'recx':xlocations,'recy':ylocations} # dictionary of prop8data\n",
    "ta = timer.time()\n",
    "t, sdata_nonoise = cmt_util.prop8seis(xtrue,ytrue,ztrue,prop8data)\n",
    "tprop = timer.time() - ta\n",
    "print(' Time taken for reference seismograms: ',tprop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculation of seismogram noise\n",
    "The Gaussian Process, GP, code `Createcurve` has by default a squared exponential GP with fixed amplitude of 0.2, defined over a 6s time window. \n",
    "\n",
    "The `corr` correlation value is interpreted relative to this 6s time window. So `corr=0.5` produces a Gaussian process with a time correlation of $\\sigma_t = 0.5/6 * \\Delta t$, where $\\Delta t$ is the time window that it is used over. In the example below $\\Delta t = 60 s$, and so $\\sigma_t = 5 s$.\n",
    "\n",
    "For `sigma_amp=0.6` the amplitude of the second Gaussian noise process becomes $A=0.6*0.2*f = 0.12*f$, which is 12% of the maximum amplitude in each window.\n",
    "\n",
    "For `sigma_amp=0.2` the amplitude of the second Gaussian noise process becomes $A=0.3*0.2*f = 0.06*f$, which is 6% of the maximum amplitude in each window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add noise to seismograms\n",
    "sigma_cor = 0.05 # noise correlation length value\n",
    "sigma_amp = 0.3 # noise amplitude scale factor (This results in 0.3*0.2=6% amplitude)\n",
    "np.random.seed(61254557) \n",
    "sdata_noise = np.zeros_like(sdata_nonoise)\n",
    "sigma = np.zeros((nr,nc))\n",
    "for i in range(nr):\n",
    "    for j in range(nc):\n",
    "        sig = sdata_nonoise[i,j,:]\n",
    "        f = np.max(np.abs(sig))\n",
    "        f = np.max(sig)-np.min(sig) \n",
    "        xc,yc = gp.Createcurve(0,nx=len(sig),corr=sigma_cor) # create a GP with amplitude 0.2 and time window +-3 s.\n",
    "        sdata_noise[i,j,:] = sig*(1.+yc*sigma_amp*f) # This was used in the first paper examples\n",
    "        sdata_noise[i,j,:] = sig +yc*sigma_amp*f     # This is a fixed amplitude noise relative to maximum window amplitude\n",
    "        sigma[i,j] = np.std(yc*sigma_amp) # Calculate actual standard deviation of noise relative to maximum seismogram amplitude "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmt_util.plotseis(sdata_noise,t,sdata_nonoise,title=' Reference seismograms (dashed) with noise added (solid)',filename='Figures/Best_fit.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This produces the noisy waveforms a subset of which are shown in Figure 10 of Sambridge et al. (2022). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prop8data['obs_seis'] = sdata_nonoise # noiseless seismogram data\n",
    "prop8data['obs_seis'] = sdata_noise   # noisy seismogram data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterative source location and moment tensor inversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we set up and solve a source location problem by minimizing seismogram misfit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup for inversion\n",
    "\n",
    "This cell makes all the choices necessary to define the inversion problem being solved. The default is to perform a location only inversion (`invopt['loc']  = True` `invopt['cmt']  = False`) and with the Wasserstein misfit function (`invopt['mistype'] = 'OT'`).\n",
    "\n",
    "Some other choices are:\n",
    "- To use an $L_2^2$ waveform misfit set `invopt['mistype'] = 'L2'`.\n",
    "- To include CMT parameters set `invopt['cmt'] = True`.\n",
    "- To calculate repeated optimisations from different starting positions set `repeatoptimisations = True` (Otherwise read in results).  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup inversion options. Controls type of problem to be solved as well as minimizer details.\n",
    "invopt,OTdata  = {},{}\n",
    "invopt['loc']  = True               # switch for inverting for source location parameters\n",
    "invopt['cmt']  = False              # switch for inverting for CMT parameters\n",
    "invopt['mistype'] = 'L2'            # style of misfit function 'L2' for L2-norm between waveforms;'OT' for Wasserstein misfit based on 2D seismogram fingerprints.\n",
    "invopt['mistype'] = 'OT'            # style of misfit function 'L2' for L2-norm between waveforms;'OT' for Wasserstein misfit based on 2D seismogram fingerprints.\n",
    "OTdata['plambda'] = 0.04            # If using OT: set density scale parameter for predicted seismogram windows\n",
    "OTdata['olambda'] = 0.04            # If using OT: set density scale parameter for observed seismogram windows\n",
    "OTdata['distfunc']='W2'             # Distance function type when using OT (W1 for p=1 Wasserstein; W2 for p=2 Wasserstein)\n",
    "OTdata['Wopt'] = 'Wavg'             # If using OT: 'Wavg' = minimize average of Wasserstein distances between marginals\n",
    "                                    #               'Wt'  = minimize Wasserstein distance between time marginals\n",
    "                                    #               'Wu'  = minimize Wasserstein distance between amplitude marginals\n",
    "OTdata['theta'] = 45.0              # angle in degrees for distance metric weighting between time and amplitude to calculate distance field\n",
    "invopt['precon'] = False            # use preconditioning of model space (rescale model parameters to approximately equalize their influence on the misfit)\n",
    "locprecon = np.array([10.,10.,20.]) # source location for gradient preconditioning  (only used if cmt and precon is True)\n",
    "# plotting and IO\n",
    "repeatoptimisations = True          # Perform repeat optimisations from different starting locations (True and slow) or read them in from pickle (False and fast)\n",
    "writepicklefile = True              # write pickle file with all results (Only makes sense if they have been calculated internally rather than read in)\n",
    "numrepeats = -1                     # Number of starting locations/cmt points to perform (-1 for all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preconditioning when inverting for both location and CMT parameters \n",
    "\n",
    "Note that when inverting for both location and CMT values, parameters have different dimensions and scales, some, e.g. Moment tensor components are far larger than the others, e.g. source location. This means that in turn gradient components can vary greatly between different unknowns, and since we are using a gradient based optimizer this in turn can have a significant influence on convergence. It makes sense then to allow for pre-conditioning, which means that the optimisation is carried out in a **rescaled** model parameter space. Here we simply decide on a set of scaling parameters for each variable and multiply the model parameters by that vector so that all optimisations are performed in that rescaled space. \n",
    "\n",
    "Ideally we would prefer all model parameters to be roughly the same size. This option is turned on by setting `invopt['precon'] = True` and scaling of model parameters is given by the values in `invopt['mscal']`, which is calculated automatically in a cell below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a reference set up I have used for inversion of location and CMT parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up starting model for optimisation\n",
    "mstart = np.array([40.,40.,10.])      # Starting model (used in paper)\n",
    "if(invopt['cmt']): \n",
    "    mstart = np.array([-40.,-40.,40.])      # Starting model\n",
    "    invopt['precon'] = True                 # use preconditioning of model space \n",
    "    locprecon = np.array([10.,10.,20.])     # source location for gradient preconditioning  (only used if cmt and precon is True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output filenames\n",
    "\n",
    "Set up filenames for pickles files to either read in previous results or calculate them and write out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle files names with previous results for display\n",
    "readpicklefilenameOT = 'pickles/OT_solutions_loc.pickle' # read this pickle file for previous OT calculations \n",
    "readpicklefilenameL2 = 'pickles/L2_solutions_loc.pickle'                       # read this pickle file for previous L2 calculations \n",
    "readpicklefilenameOTcmt = 'pickles/OT_solutions_cmt.pickle' # read this pickle file for previous OT calculations and inverting for cmt\n",
    "readpicklefilenameL2cmt = 'pickles/L2_solutions_cmt.pickle' # read this pickle file for previous L2 calculations and inverting for cmt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filenames of plots and pickles files\n",
    "rootname = 'Figures/misfit_solution_'\n",
    "fileformat = '.pdf'\n",
    "if(invopt['cmt']): rootname = 'Figures/misfit_solution_cmt_'\n",
    "picklefilename = invopt['mistype']+'_solutions_loc.pickle'\n",
    "if(invopt['cmt']): picklefilename = invopt['mistype']+'_solutions_cmt.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup inversion options dictionary \n",
    "# If using OT: set density scale parameter for observed seismogram windows\n",
    "\n",
    "obs_grids = cmt_util.buildFingerprintwindows(t,prop8data['obs_seis'])                                             # set up Fingerprint windows about each waveform\n",
    "OTdata['obs_grids01'] = cmt_util.buildFingerprintwindows(t,prop8data['obs_seis'],u0=0.,u1=1.0)                    # set up Fingerprint windows about each waveform\n",
    "wfobs, wfobs_target = cmt_util.BuildOTobjfromWaveform(t,prop8data['obs_seis'],obs_grids,OTdata,lambdav=OTdata['olambda'],theta=OTdata['theta']) # build observed data object for OT calculations containing all waveforms\n",
    "OTdata['wfobs'] =wfobs\n",
    "OTdata['wfobs_target']=wfobs_target\n",
    "OTdata['obs_grids'] = obs_grids # fingerprint window and grid used for observations\n",
    "mtrue = cmt_util.setmref(invopt,source,mtrue)\n",
    "invopt['mref'] = mtrue\n",
    "optdata = {'invopt':invopt,'OTdata':OTdata,'prop8data':prop8data}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up starting model for optimisation\n",
    "mstart = np.array([40.,40.,10.])      # L2 fails with 5% Gausian noise; OT succeeds (used in paper)\n",
    "if(invopt['cmt']): \n",
    "    mstart = np.array([-40.,-40.,40.])      # L2 fails and OT converges\n",
    "    invopt['precon'] = True                 # use preconditioning of model space \n",
    "    locprecon = np.array([10.,10.,20.])     # source location for gradient preconditioning  (only used if cmt and precon is True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform some preliminary work now we have starting model\n",
    "\n",
    "if(invopt['cmt']): # set initial CMT solution to best fit at starting model\n",
    "    mstart = np.append(mstart,cmt_util.Moment_LS([mstart[0],mstart[1],mstart[2]],prop8data))\n",
    "\n",
    "if(invopt['precon']): # turn on preconditioning of model space \n",
    "    invopt['mprecon'] = [locprecon[0],locprecon[1],locprecon[2]]\n",
    "    # Note that we cannot set the preconditioning location to the same model as the CMT solution for L2 because the gradients will be near zero, which damages the preconditioning (divide by near zero)\n",
    "    invopt['precontype'] = 'gradient' # precondition model parameters using gradient of the misfit at a location\n",
    "    invopt['precontype'] = 'constant' # precondition model parameters using a constant\n",
    "    if(invopt['precontype']=='gradient'): # gradient preconditining\n",
    "        mprecon = np.append(invopt['mprecon'],cmt_util.Moment_LS([invopt['mprecon'][0],invopt['mprecon'][1],invopt['mprecon'][2]],prop8data)) # set model used for preconditioning to mprecon model\n",
    "        w,dw = cmt_util.optfunc(mprecon,optdata,precon=False) # use  gradient for preconditioning\n",
    "    elif(invopt['precontype']=='constant'):\n",
    "        dw = np.append(np.ones(3)/60.,np.ones(6)/(Mo*Nm2moment)) # set model used for preconditioning to start model\n",
    "    invopt['mscal'] = 1./np.abs(dw)    \n",
    "    mstartp = mstart/invopt['mscal'] # preconditioned starting model \n",
    "\n",
    "else:\n",
    "    invopt['mscal'] = np.ones_like(mstart)\n",
    "    mstartp = mstart                  # unpreconditioned starting model\n",
    "\n",
    "optdata = {'invopt':invopt,'OTdata':OTdata,'prop8data':prop8data} # update inversion options dictionary\n",
    "mis_true,dW = cmt_util.optfunc(mtrue,optdata,precon=False) # test opt func at True location\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeat optimisation for different starting positions and misfit types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starts = [np.array([-80.,-80.,40.]),\n",
    "          np.array([-80.,-80.,30.]),\n",
    "          np.array([-80.,-80.,20.]),\n",
    "          np.array([-80.,-80.,10.]),\n",
    "          np.array([-60.,-60.,40.]),\n",
    "          np.array([-60.,-60.,30.]),\n",
    "          np.array([-60.,-60.,20.]),\n",
    "          np.array([-60.,-60.,10.]),\n",
    "          np.array([-40.,-40.,40.]),\n",
    "          np.array([-40.,-40.,30.]),\n",
    "          np.array([-40.,-40.,20.]),\n",
    "          np.array([-40.,-40.,10.]),\n",
    "          np.array([-20.,-20.,40.]),\n",
    "          np.array([-20.,-20.,30.]),\n",
    "          np.array([-20.,-20.,20.]),\n",
    "          np.array([-20.,-20.,10.]),\n",
    "          np.array([20.,20.,40.]),\n",
    "          np.array([20.,20.,30.]),\n",
    "          np.array([20.,20.,20.]),\n",
    "          np.array([20.,20.,10.]),\n",
    "          np.array([40.,40.,40.]),\n",
    "          np.array([40.,40.,30.]),\n",
    "          np.array([40.,40.,20.]),\n",
    "          np.array([40.,40.,10.]),\n",
    "          np.array([60.,60.,40.]),\n",
    "          np.array([60.,60.,30.]),\n",
    "          np.array([60.,60.,20.]),\n",
    "          np.array([60.,60.,10.]),\n",
    "          np.array([80.,80.,40.]),\n",
    "          np.array([80.,80.,30.]),\n",
    "          np.array([80.,80.,20.]),\n",
    "          np.array([80.,80.,10.]),\n",
    "          np.array([-80.,80.,40.]),\n",
    "          np.array([-80.,80.,30.]),\n",
    "          np.array([-80.,80.,20.]),\n",
    "          np.array([-80.,80.,10.]),\n",
    "          np.array([-60.,60.,40.]),\n",
    "          np.array([-60.,60.,30.]),\n",
    "          np.array([-60.,60.,20.]),\n",
    "          np.array([-60.,60.,10.]),\n",
    "          np.array([-40.,40.,40.]),\n",
    "          np.array([-40.,40.,30.]),\n",
    "          np.array([-40.,40.,20.]),\n",
    "          np.array([-40.,40.,10.]),\n",
    "          np.array([-20.,20.,40.]),\n",
    "          np.array([-20.,20.,30.]),\n",
    "          np.array([-20.,20.,20.]),\n",
    "          np.array([-20.,20.,10.]),\n",
    "          np.array([20.,-20.,40.]),\n",
    "          np.array([20.,-20.,30.]),\n",
    "          np.array([20.,-20.,20.]),\n",
    "          np.array([20.,-20.,10.]),\n",
    "          np.array([40.,-40.,40.]),\n",
    "          np.array([40.,-40.,30.]),\n",
    "          np.array([40.,-40.,20.]),\n",
    "          np.array([40.,-40.,10.]),\n",
    "          np.array([60.,-60.,40.]),\n",
    "          np.array([60.,-60.,30.]),\n",
    "          np.array([60.,-60.,20.]),\n",
    "          np.array([60.,-60.,10.]),\n",
    "          np.array([80.,-80.,40.]),\n",
    "          np.array([80.,-80.,30.]),\n",
    "          np.array([80.,-80.,20.]),\n",
    "          np.array([80.,-80.,10.])\n",
    "         ]\n",
    "solutions = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(repeatoptimisations):   # Perform repeat optimisations from different starting positions. \n",
    "    if(invopt['loc']): print('\\n Inverting for source location')\n",
    "    if(invopt['cmt']): \n",
    "        print(' Inverting for moment tensor using gradient optimisation ')\n",
    "    elif(invopt['cmt']): \n",
    "        print(' Inverting for moment tensor using linear theory')\n",
    "    print(' Dimension of parameter space :',len(mstartp))\n",
    "    if(invopt['precon']): \n",
    "        print(' Gradient preconditioning being used about point',invopt['mprecon'])\n",
    "    if(invopt['mistype']=='OT'): print(' Misfit function: ',OTdata['Wopt'])\n",
    "    if(invopt['mistype']=='L2'): print(' Misfit function: L2')\n",
    "    print('\\n Running optimizations.....\\n')\n",
    "    \n",
    "\n",
    "    for mstart in starts[:numrepeats]:\n",
    "        if(invopt['cmt'] ): mstart = np.append(mstart,cmt_util.Moment_LS([mstart[0],mstart[1],mstart[2]],prop8data)) # set initial CMT solution to best fit at starting model\n",
    "\n",
    "        mis_start,d = cmt_util.optfunc(mstart,optdata,precon=False) # Calculate misfit for reference source\n",
    "\n",
    "        if(invopt['loc'] and not invopt['cmt']):\n",
    "\n",
    "            cmt_util_opt.opt_history = [mstart,mis_start,-1]\n",
    "    \n",
    "            # start inversion\n",
    "\n",
    "            if(OTdata['Wopt'] == 'both'): # perform optimisation over Wu and then Wt\n",
    "                OTdata['Wopt'] = 'Wt'\n",
    "                optdata = {'invopt':invopt,'OTdata':OTdata,'prop8data':prop8data}\n",
    "        \n",
    "                opt1 = minimize(cmt_util.optfunc, mstart, optdata, jac=True, tol=1E-5*mis_start,method='L-BFGS-B',\n",
    "                   options={'disp': True,'maxiter': 500},callback=recordresult)\n",
    "\n",
    "                OTdata['Wopt'] = 'Wu'\n",
    "                optdata = {'invopt':invopt,'OTdata':OTdata,'prop8data':prop8data}\n",
    "\n",
    "                opt = minimize(cmt_util.optfunc, opt1.x, optdata, jac=True, tol=1E-5*mis_start,method='L-BFGS-B',\n",
    "                       options={'disp': True,'maxiter': 500},callback=recordresult)\n",
    "\n",
    "                OTdata['Wopt'] = 'both'\n",
    "        \n",
    "            else: # perform optimisation over either Wu, Wt or their average\n",
    "                opt = minimize(cmt_util.optfunc, mstart, optdata, jac=True, tol=1E-5*mis_start,method='L-BFGS-B',\n",
    "                       options={'disp': True,'maxiter': 500},callback=recordresult)\n",
    "                        \n",
    "            #print(opt)\n",
    "            sol = opt.x\n",
    "    \n",
    "        elif(invopt['loc'] and invopt['cmt']): # Here cmt is obtained from least squares inversion at best fit source location.\n",
    "\n",
    "            cmt_util_opt.opt_history = [mstart,mis_start,-1]\n",
    "\n",
    "\n",
    "            if(invopt['precon']): mstartp = mstart/invopt['mscal'] # preconditioned starting model\n",
    "            opt = minimize(cmt_util.optfunc, mstartp, optdata, jac=True, tol=1E-5*mis_start,method='L-BFGS-B',\n",
    "                    options={'disp': True,'maxiter': 500},callback=recordresult)\n",
    "            \n",
    "            print(opt)\n",
    "            sol = opt.x\n",
    "            if(invopt['precon']): sol = opt.x*invopt['mscal']\n",
    "            \n",
    "        elif(invopt['cmt']):\n",
    "    \n",
    "            # start inversion\n",
    "\n",
    "            Mxyz = cmt_util.Moment_LS([xtrue,ytrue,ztrue],optdata[0])\n",
    "            Mxyz = cmt_util.buildMxyzfromupper(Mxyz)\n",
    "    \n",
    "            print (' Mxyz solution: \\n',Mxyz)\n",
    "\n",
    "        mis_final = opt.fun\n",
    "        mfinal = sol\n",
    "        print('\\n Model start :',mstart,' Misfit start :',mis_start,' Misfit final :',mis_final,' Misfit true :',mis_true)\n",
    "        solutions += [[mstart,mis_start,mfinal,mis_final,mtrue,mis_true,cmt_util_opt.opt_history_data[-1][4]]]\n",
    "        #if(invopt['cmt']): printanalysis(sol,opt,mtrue)\n",
    "        if(invopt['cmt']):cmt_util.printanalysis(sol,opt,mtrue,mstart,mis_start,mis_true,prop8data,sdata_nonoise)\n",
    "        print('\\n Misfit start   :',mis_start)\n",
    "        print(' Misfit final     :',mis_final)\n",
    "        print(' Misfit true      :',mis_true)\n",
    "        r=np.array(mtrue[:3])-sol[:3]\n",
    "        print(' Distance to true :',np.sqrt(np.dot(r,r)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write out pickle data for all results\n",
    "if(writepicklefile):\n",
    "    listOfStr = ['solutions']\n",
    "    listOfdata = [solutions]\n",
    "    cmt_util.writepickle('pickles/'+picklefilename,listOfStr,listOfdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis of convergence rates in optimisation\n",
    "\n",
    "Here we compare convergence rates of source location from different starting points. \n",
    "\n",
    "**Note that you can only run this part of the notebook if you have previously calculated a W2 and an L2 set of solutions for either location only or location and CMT parameters**\n",
    "\n",
    "To read and display location only repeat solutions set `convergenceplotcmt = False`; otherwise it will read and display the location+cmt repeat solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convergenceplots = True # plot convergence of locations from pickles file\n",
    "convergenceplotcmt = True # switch to plot cmt solutions\n",
    "# read in previously calculated relocation solutions from pickle file\n",
    "if(convergenceplots):\n",
    "    if(convergenceplotcmt):\n",
    "        po = cmt_util.readpickle(readpicklefilenameOTcmt) # previous OT cmt solutions\n",
    "        poL2 = cmt_util.readpickle(readpicklefilenameL2cmt) # previous L2 cmt solutions\n",
    "    else: \n",
    "        po = cmt_util.readpickle(readpicklefilenameOT) # previous OT location only solutions \n",
    "        poL2 = cmt_util.readpickle(readpicklefilenameL2) # previous L2 location only solutions \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlimit = 2.5  # set distance limit for convergence with location only (Gaussian noise dataset)\n",
    "if(convergenceplotcmt): dlimit = 1.0 # set distance limit for convergence cmt with optimisation in 9 d space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine which solutions using Wasserstein misfit have converged\n",
    "con,d,gcon = cmt_util.checkconverge(solutions,dlimit=dlimit)\n",
    "# determine which solutions from L2 misfit have converged\n",
    "conL2,dL2,gconL2 = cmt_util.checkconverge(poL2['solutions'],dlimit=dlimit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convergence plot\n",
    "if(convergenceplotcmt):\n",
    "    d0x = 0.4\n",
    "    d0y = 0.4\n",
    "    d1x = 200.\n",
    "    d1y = 200.\n",
    "else:\n",
    "    d0x = 0.5\n",
    "    d0y = 0.5\n",
    "    d0x = 1.5\n",
    "    d0y = 1.5\n",
    "    d1x = 200.\n",
    "    d1y = 200.\n",
    "\n",
    "fig, axs = plt.subplots(1, 1, tight_layout=True,figsize=(6,6))\n",
    "plt.gca().set_aspect('equal')\n",
    "axs.set_xlim(d0x,d1x)\n",
    "axs.set_ylim(d0y,d1y)\n",
    "axs.loglog([d0x,d1x],[d0y,d1y],'k:')\n",
    "x = np.linspace(1,len(d),len(d))\n",
    "axs.loglog([dlimit,dlimit],[d0y,d1y],'g:')\n",
    "axs.loglog([d0x,185.],[dlimit,dlimit],'g:')\n",
    "axs.loglog(np.sort(d),np.sort(dL2),'D-',markersize=5.)\n",
    "axs.set_xlabel('Error in OT solution (km)',fontsize=15.)\n",
    "axs.set_ylabel('Error in L2 solution (km)',fontsize=15.)\n",
    "plt.savefig('Figures/Solution_error_L2_vs_OT_log.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This produces one of the panels in Figure 12 of Sambridge et al. (2022). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
